{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2d2caff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial models fitted successfully!\n",
      "Predictions generated successfully!\n",
      "Performance metrics calculated successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.458s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance metrics saved to the database!\n",
      "Best Ideal Columns:\n",
      "y1: y48\n",
      "y2: y31\n",
      "y3: y30\n",
      "y4: y40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.transform import dodge\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import unittest\n",
    "\n",
    "class DataAnalysis:\n",
    "#Data analysis class for performing data analysis tasks.\n",
    "\n",
    "    def __init__(self, train_file, ideal_file, test_file):\n",
    "        self.train_file = train_file\n",
    "        self.ideal_file = ideal_file\n",
    "        self.test_file = test_file\n",
    "        self.train_data = None\n",
    "        self.ideal_data = None\n",
    "        self.test_data = None\n",
    "\n",
    "    def read_data(self):\n",
    "        #Read data from CSV files\n",
    "        self.train_data = pd.read_csv(self.train_file)\n",
    "        self.ideal_data = pd.read_csv(self.ideal_file)\n",
    "        self.test_data = pd.read_csv(self.test_file)\n",
    "\n",
    "    def visualize_training_data(self):\n",
    "        #Visualize the training data using Bokeh library\n",
    "        p = figure(title='Training Data', x_axis_label='x', y_axis_label='y', width=500, height=300)\n",
    "        p.circle(self.train_data['x'], self.train_data['y1'], legend_label='y1', size=4, color='blue')\n",
    "        p.circle(self.train_data['x'], self.train_data['y2'], legend_label='y2', size=4, color='red')\n",
    "        p.circle(self.train_data['x'], self.train_data['y3'], legend_label='y3', size=4, color='green')\n",
    "        p.circle(self.train_data['x'], self.train_data['y4'], legend_label='y4', size=4, color='orange')\n",
    "        show(p)\n",
    "\n",
    "    def visualize_test_data(self):\n",
    "        #Visualize the test data using Bokeh library\n",
    "        p = figure(title='Test Data', x_axis_label='x', y_axis_label='y', width=500, height=300)\n",
    "        p.circle(self.test_data['x'], self.test_data['y'], legend_label='y', size=4, color='purple')\n",
    "        show(p)\n",
    "\n",
    "    def fit_polynomial_models(self):\n",
    "        models = {}\n",
    "        for col in self.train_data.columns[1:]:\n",
    "            #Fit a polynomial model to each column in the training data\n",
    "            model = np.polyfit(self.train_data['x'], self.train_data[col], 3)\n",
    "            models[col] = model\n",
    "        return models\n",
    "\n",
    "    def predict(self, models):\n",
    "        predictions = {}\n",
    "        for col, model in models.items():\n",
    "            poly_func = np.poly1d(model)\n",
    "            #Predict the values for each column in the test data \n",
    "            predictions[col] = poly_func(self.test_data['x'])\n",
    "        return predictions\n",
    "\n",
    "    def calculate_performance_metrics(self, models):\n",
    "        metrics = {}\n",
    "        for col, model in models.items():\n",
    "            predictions = self.predict({col: model})\n",
    "            y_true = self.test_data['y']\n",
    "            y_pred = predictions[col]\n",
    "            #Calculate performance metrics for each column\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "            r2 = r2_score(y_true, y_pred)\n",
    "            metrics[col] = {'MAE': mae, 'MSE': mse, 'R2 Score': r2}\n",
    "        return metrics\n",
    "\n",
    "    def plot_performance_metrics(self, metrics):\n",
    "        names = list(metrics.keys())\n",
    "        mae_values = [metrics[name]['MAE'] for name in names]\n",
    "        mse_values = [metrics[name]['MSE'] for name in names]\n",
    "        r2_values = [metrics[name]['R2 Score'] for name in names]\n",
    "        data = dict(names=names, mae_values=mae_values, mse_values=mse_values, r2_values=r2_values)\n",
    "        #width of each bar\n",
    "        bar_width = 0.4\n",
    "        offset = 0.4\n",
    "\n",
    "        #Creating the figure\n",
    "        p = figure(x_range=names, width=600, height=400, title='Performance Metrics')\n",
    "        p.xaxis.axis_label = 'Columns'\n",
    "        p.yaxis.axis_label = 'Metric Value'\n",
    "\n",
    "        #Ploting the performance metrics (MAE, MSE, R2 Score)\n",
    "        p.vbar(x=dodge('names', -bar_width-offset, range=p.x_range), top='mae_values', width=bar_width,\n",
    "               source=ColumnDataSource(data), color='blue', legend_label='MAE')\n",
    "\n",
    "        p.vbar(x=dodge('names', -offset, range=p.x_range), top='mse_values', width=bar_width,\n",
    "               source=ColumnDataSource(data), color='green', legend_label='MSE')\n",
    "\n",
    "        p.vbar(x=dodge('names', bar_width+offset, range=p.x_range), top='r2_values', width=bar_width,\n",
    "               source=ColumnDataSource(data), color='orange', legend_label='R2 Score')\n",
    "\n",
    "        #Show figure\n",
    "        p.legend.location = 'top_right'\n",
    "        show(p)\n",
    "\n",
    "\n",
    "    def save_to_database(self, metrics):\n",
    "        #Saving the performance metrics to database using SQLAlchemy\n",
    "        engine = create_engine('sqlite:///metrics.db')\n",
    "        with engine.begin() as conn:\n",
    "            for col, values in metrics.items():\n",
    "                df = pd.DataFrame(values, index=[col])\n",
    "                df.to_sql('metrics', conn, if_exists='append')\n",
    "\n",
    "    def find_best_ideal_functions(self):\n",
    "        ideal_functions = {}\n",
    "        for y_col in self.train_data.columns[1:]:\n",
    "            differences = {}\n",
    "            for ideal_col in self.ideal_data.columns[1:]:\n",
    "                #Calculating the difference between the train data column and each ideal data column\n",
    "                difference = np.sum(np.abs(self.train_data[y_col] - self.ideal_data[ideal_col]))\n",
    "                differences[ideal_col] = difference\n",
    "            best_ideal_col = min(differences, key=differences.get)\n",
    "            ideal_functions[y_col] = best_ideal_col\n",
    "        return ideal_functions\n",
    "\n",
    "    def print_ideal_columns(self):\n",
    "        # Find the best ideal column for each train data column and print the results\n",
    "        ideal_functions = self.find_best_ideal_functions()\n",
    "        print(\"Best Ideal Columns:\")\n",
    "        for y_col, ideal_col in ideal_functions.items():\n",
    "            print(f\"{y_col}: {ideal_col}\")\n",
    "\n",
    "class DataAnalysisWrapper:\n",
    "#Wrapper class for data analysis.\n",
    "    \n",
    "\n",
    "    def __init__(self, train_file, ideal_file, test_file):\n",
    "        self.train_file = train_file\n",
    "        self.ideal_file = ideal_file\n",
    "        self.test_file = test_file\n",
    "        self.analysis = None\n",
    "\n",
    "    def perform_data_analysis(self):\n",
    "        # Performing the data analysis\n",
    "        self.load_data()\n",
    "        self.visualize_data()\n",
    "        models = self.fit_models()\n",
    "        predictions = self.predict_values(models)\n",
    "        metrics = self.calculate_metrics(models)\n",
    "        self.plot_metrics(metrics)\n",
    "        self.save_metrics(metrics)\n",
    "        self.print_ideal_columns()\n",
    "\n",
    "    def load_data(self):\n",
    "        #Create an instance of DataAnalysis class\n",
    "        #load the data\n",
    "        analysis = DataAnalysis(self.train_file, self.ideal_file, self.test_file)\n",
    "        analysis.read_data()\n",
    "        self.analysis = analysis\n",
    "\n",
    "    def visualize_data(self):\n",
    "        #Visualize the training and test data\n",
    "        self.analysis.visualize_training_data()\n",
    "        self.analysis.visualize_test_data()\n",
    "\n",
    "    def fit_models(self):\n",
    "        #Fit polynomial models to the training data\n",
    "        models = self.analysis.fit_polynomial_models()\n",
    "        print(\"Polynomial models fitted successfully!\")\n",
    "        return models\n",
    "\n",
    "    def predict_values(self, models):\n",
    "        #Generate predictions for the test data\n",
    "        predictions = self.analysis.predict(models)\n",
    "        print(\"Predictions generated successfully!\")\n",
    "        return predictions\n",
    "\n",
    "    def calculate_metrics(self, models):\n",
    "        #Calculate performance metrics for the predictions\n",
    "        metrics = self.analysis.calculate_performance_metrics(models)\n",
    "        print(\"Performance metrics calculated successfully!\")\n",
    "        return metrics\n",
    "\n",
    "    def plot_metrics(self, metrics):\n",
    "        #Plot the performance metrics\n",
    "        self.analysis.plot_performance_metrics(metrics)\n",
    "\n",
    "    def save_metrics(self, metrics):\n",
    "        #Save the performance metrics to a database\n",
    "        self.analysis.save_to_database(metrics)\n",
    "        print(\"Performance metrics saved to the database!\")\n",
    "\n",
    "    def print_ideal_columns(self):\n",
    "        #Print best ideal columns for each train data column\n",
    "        self.analysis.print_ideal_columns()\n",
    "\n",
    "#Load data set\n",
    "train_file = 'train.csv'\n",
    "ideal_file = 'ideal.csv'\n",
    "test_file = 'test.csv'\n",
    "\n",
    "class TestDataAnalysis(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.train_file = 'train.csv'\n",
    "        self.ideal_file = 'ideal.csv'\n",
    "        self.test_file = 'test.csv'\n",
    "\n",
    "    def test_data_analysis(self):\n",
    "        wrapper = DataAnalysisWrapper(self.train_file, self.ideal_file, self.test_file)\n",
    "        wrapper.perform_data_analysis()\n",
    "\n",
    "        # Add assertions to test the expected outcomes\n",
    "        # For example, check if the metrics are calculated and saved successfully\n",
    "        self.assertIsNotNone(wrapper.analysis.calculate_performance_metrics(wrapper.analysis.fit_polynomial_models()))\n",
    "        # ...\n",
    "\n",
    "\n",
    "#Create a test suite\n",
    "test_suite = unittest.TestLoader().loadTestsFromTestCase(TestDataAnalysis)\n",
    "\n",
    "#Run the tests\n",
    "unittest.TextTestRunner().run(test_suite)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5788c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
